{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import torch\n",
    "import torch.utils.data\n",
    "import torchvision\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib as mpl\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ti = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(y_true, y_pred, classes,\n",
    "                          normalize=False,\n",
    "                          title=None,\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \n",
    "    Modified by M. Romero.\n",
    "    Original: https://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html#sphx-glr-auto-examples-model-selection-plot-confusion-matrix-py\n",
    "    \"\"\"\n",
    "    if not title:\n",
    "        if normalize:\n",
    "            title = 'Normalized confusion matrix'\n",
    "        else:\n",
    "            title = 'Confusion matrix, without normalization'\n",
    "\n",
    "    # Compute confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    # Only use the labels that appear in the data\n",
    "    #classes = classes[unique_labels(y_true, y_pred)]\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10, 10))\n",
    "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    ax.figure.colorbar(im, ax=ax)\n",
    "    # We want to show all ticks...\n",
    "    ax.set(xticks=np.arange(cm.shape[1]),\n",
    "           yticks=np.arange(cm.shape[0]),\n",
    "           # ... and label them with the respective list entries\n",
    "           xticklabels=classes, yticklabels=classes,\n",
    "           title=title,\n",
    "           ylabel='True label',\n",
    "           xlabel='Predicted label')\n",
    "\n",
    "    # Rotate the tick labels and set their alignment.\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
    "             rotation_mode=\"anchor\")\n",
    "\n",
    "    # Loop over data dimensions and create text annotations.\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            ax.text(j, i, format(cm[i, j], fmt),\n",
    "                    ha=\"center\", va=\"center\",\n",
    "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    fig.tight_layout()\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpl.rc(\"font\", size=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "cuda = True\n",
    "device = torch.device(\"cuda:0\" if cuda and torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Carga del dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "digits = load_digits()\n",
    "targets = digits.target\n",
    "data = digits.data\n",
    "classes = digits.target_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Division train-val-test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 70 %\n",
      "val 10 %\n",
      "test 20 %\n"
     ]
    }
   ],
   "source": [
    "# train-validation-test split\n",
    "nsamples, ndim = data.shape\n",
    "nlabels = len(classes)\n",
    "indexes = np.arange(nsamples)\n",
    "train_idx, test_idx = train_test_split(indexes, test_size=0.2)\n",
    "train_idx, val_idx = train_test_split(train_idx, test_size=0.1/0.8)\n",
    "\n",
    "print(\"train {:.0f} %\".format(len(train_idx)/nsamples*100))\n",
    "print(\"val {:.0f} %\".format(len(val_idx)/nsamples*100))\n",
    "print(\"test {:.0f} %\".format(len(test_idx)/nsamples*100))\n",
    "\n",
    "x_train = data[train_idx]\n",
    "x_val = data[val_idx]\n",
    "x_test = data[test_idx]\n",
    "\n",
    "y_train = targets[train_idx]\n",
    "y_val = targets[val_idx]\n",
    "y_test = targets[test_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalizacion de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scaler = StandardScaler() # (x - mu)/std, (mu, std) = (0, 1)\n",
    "scaler = MinMaxScaler()\n",
    "x_train = scaler.fit_transform(x_train)\n",
    "x_val = scaler.transform(x_val)\n",
    "x_test = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Declaracion de tensores y dispositivo de trabajo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "cuda = False\n",
    "device = torch.device(\"cuda:0\" if cuda and torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = torch.tensor(x_train, device=device, dtype=torch.float)\n",
    "x_val = torch.tensor(x_val, device=device, dtype=torch.float)\n",
    "x_test = torch.tensor(x_test, device=device, dtype=torch.float)\n",
    "\n",
    "y_train = torch.tensor(y_train, device=device, dtype=torch.long) # ojo que al utilizar CrossEntropyLoss \n",
    "y_val = torch.tensor(y_val, device=device, dtype=torch.long)     # la entrada debe ser tipo long\n",
    "y_test = torch.tensor(y_test, device=device, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Declaracion de dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = torch.utils.data.TensorDataset(x_train, y_train)\n",
    "val_dataset = torch.utils.data.TensorDataset(x_val, y_val)\n",
    "test_dataset = torch.utils.data.TensorDataset(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Construccion de red neuronal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(torch.nn.Module):\n",
    "    def __init__(self, ninput, nhidden, nout, bn=False, do=False):\n",
    "        super(MLP, self).__init__()\n",
    "        layers = []\n",
    "        layers.append(torch.nn.Linear(ninput, nhidden))\n",
    "        layers.append(torch.nn.BatchNorm1d(nhidden)) if bn else 0\n",
    "        layers.append(torch.nn.Dropout(0.5)) if do else 0\n",
    "        layers.append(torch.nn.ReLU())\n",
    "        layers.append(torch.nn.Linear(nhidden, nout))\n",
    "        self.mlp = torch.nn.Sequential(*layers)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.mlp(x)\n",
    "    \n",
    "    \n",
    "class AE(torch.nn.Module):\n",
    "    def __init__(self, nin, nl, bn=False, do=False):\n",
    "        super(AE, self).__init__()\n",
    "        self.enc1 = torch.nn.Linear(nin, 32)\n",
    "        self.enc2 = torch.nn.Linear(32, nl)\n",
    "        self.dec1 = torch.nn.Linear(32, nin)\n",
    "        self.dec2 = torch.nn.Linear(nl, 32)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        self.sig = torch.nn.Sigmoid()\n",
    "    \n",
    "    def encode(self, x):\n",
    "        e1 = self.relu(self.enc1(x))\n",
    "        return self.enc2(e1)\n",
    "    \n",
    "    def decode(self, u):\n",
    "        d1 = self.relu(self.dec2(u))\n",
    "        return self.sig(self.dec1(d1))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        l = self.encode(x)\n",
    "        r = self.decode(l)\n",
    "        return l, r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decalaracion de hiper parametros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 2e-4\n",
    "wd = 0.\n",
    "bs = 100\n",
    "neurons = 100\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\mauricio\\anaconda3\\envs\\color\\lib\\site-packages\\ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "c:\\users\\mauricio\\anaconda3\\envs\\color\\lib\\site-packages\\ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "transform = [torchvision.transforms.ToTensor()]\n",
    "\n",
    "N = 10000\n",
    "\n",
    "trainset = torchvision.datasets.MNIST(root=\"../datasets/mnist/train\", train=True, download=True, transform=torchvision.transforms.Compose(transform))\n",
    "testset = torchvision.datasets.MNIST(root=\"../datasets/mnist/test\", train=False, download=True, transform=torchvision.transforms.Compose(transform))\n",
    "\n",
    "train_tensor = torch.tensor(trainset.data)[:N].float().to(device).reshape(N, -1)/255.\n",
    "test_tensor = torch.tensor(testset.data)[:N].float().to(device).reshape(N, -1)/255.\n",
    "\n",
    "trainDataset = torch.utils.data.TensorDataset(train_tensor, trainset.targets[:N].to(device))\n",
    "testDataset = torch.utils.data.TensorDataset(test_tensor, testset.targets[:N].to(device))\n",
    "\n",
    "trainLoader = torch.utils.data.DataLoader(trainDataset, batch_size=4, shuffle=True)\n",
    "testLoader = torch.utils.data.DataLoader(testDataset, batch_size=4, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Declaracion de dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ntrain_loader = torch.utils.data.DataLoader(train_dataset, batch_size=bs, shuffle=True)\\nval_loader = torch.utils.data.DataLoader(val_dataset, batch_size=bs, shuffle=True)\\ntest_loader = torch.utils.data.DataLoader(test_dataset, batch_size=bs, shuffle=True)\\n'"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=bs, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=bs, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=bs, shuffle=True)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Funcion de perdida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "cel = torch.nn.CrossEntropyLoss().to(device)\n",
    "bcel = torch.nn.BCELoss().to(device)\n",
    "msel = torch.nn.MSELoss().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Funcion de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_my_model(epochs, model, optimizer, loss_function, trainloader, valloader, testloader):\n",
    "    losses = np.zeros((epochs, 3))\n",
    "    best_val_loss = np.inf\n",
    "    for epoch in range(epochs):\n",
    "        train_loss = 0\n",
    "        val_loss = 0\n",
    "        test_loss = 0\n",
    "        model.train()\n",
    "        for i, batch in enumerate(trainloader):\n",
    "            x_in, y_in = batch\n",
    "            _, x_out = model(x_in)\n",
    "            loss = loss_function(x_out, x_in)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "        train_loss /= i + 1\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            if valloader != None:\n",
    "                for i, batch in enumerate(valloader):\n",
    "                    x_in, y_in = batch\n",
    "                    _, x_out = model(x_in)\n",
    "                    loss = loss_function(x_out, x_in)\n",
    "                    val_loss += loss.item()\n",
    "                val_loss /= i + 1\n",
    "            for i, batch in enumerate(testloader):\n",
    "                x_in, y_in = batch\n",
    "                _, x_out = model(x_in)\n",
    "                loss = loss_function(x_out, x_in)\n",
    "                test_loss += loss.item()\n",
    "            test_loss /= i + 1\n",
    "        losses[epoch] = [train_loss, val_loss, test_loss]\n",
    "        print(\"Epoch {} Train loss {:.3f} Val loss {:.3f} Test loss {:.3f}\".format(epoch, train_loss, val_loss, test_loss))\n",
    "        if valloader != None:\n",
    "            if val_loss < best_val_loss:\n",
    "                print(\"Saving\")\n",
    "                torch.save(model.state_dict(), \"models/ae.pth\")\n",
    "                best_val_loss = val_loss\n",
    "        else:\n",
    "            if test_loss < best_val_loss:\n",
    "                print(\"Saving\")\n",
    "                torch.save(model.state_dict(), \"models/ae.pth\")\n",
    "                best_val_loss = test_loss\n",
    "    return losses\n",
    "\n",
    "\n",
    "def plot_my_loss(loss, title, ylabel=\"mean cross entropy\"):\n",
    "    plt.figure(figsize=(20, 5))\n",
    "    plt.plot(loss[:, 0], color=\"navy\", label=\"train\")\n",
    "    plt.plot(loss[:, 1], color=\"green\", label=\"val\")\n",
    "    plt.plot(loss[:, 2], color=\"red\", label=\"test\")\n",
    "    plt.xlabel(\"epochs\")\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "    plt.ylim([0, 2])\n",
    "    return\n",
    "\n",
    "\n",
    "def eval_my_model(model, test_data):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        xl, x_out = model(test_data)\n",
    "    return xl.cpu().numpy(), x_out.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Train loss 0.334 Val loss 0.000 Test loss 0.275\n",
      "Saving\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-120-95e25e118f14>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mmodel_bce\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mAE\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_tensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0moptimizer_bce\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAdamax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_bce\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight_decay\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mwd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mloss_bce\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_my_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel_bce\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer_bce\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbcel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrainLoader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtestLoader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mmodel_bce\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"models/ae.pth\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-119-db7afea04d9f>\u001b[0m in \u001b[0;36mtrain_my_model\u001b[1;34m(epochs, model, optimizer, loss_function, trainloader, valloader, testloader)\u001b[0m\n\u001b[0;32m     12\u001b[0m             \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_out\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_in\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m             \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m             \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m             \u001b[0mtrain_loss\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[0mtrain_loss\u001b[0m \u001b[1;33m/=\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\mauricio\\anaconda3\\envs\\color\\lib\\site-packages\\torch\\optim\\adamax.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, closure)\u001b[0m\n\u001b[0;32m     73\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m                 \u001b[1;31m# Update biased first moment estimate.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 75\u001b[1;33m                 \u001b[0mexp_avg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbeta1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mbeta1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     76\u001b[0m                 \u001b[1;31m# Update the exponentially weighted infinity norm.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     77\u001b[0m                 norm_buf = torch.cat([\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model_bce = AE(train_tensor.shape[1], 2).to(device)\n",
    "optimizer_bce = torch.optim.Adamax(model_bce.parameters(), lr=lr, weight_decay=wd)\n",
    "loss_bce = train_my_model(epochs, model_bce, optimizer_bce, bcel, trainLoader, None, testLoader)\n",
    "model_bce.load_state_dict(torch.load(\"models/ae.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_mse = AE(train_tensor.shape[1], 2).to(device)\n",
    "optimizer_mse = torch.optim.Adamax(model_mse.parameters(), lr=lr, weight_decay=wd)\n",
    "loss_mse = train_my_model(epochs, model_mse, optimizer_mse, msel, trainLoader, None, testLoader)\n",
    "model_mse.load_state_dict(torch.load(\"models/ae.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xl_bce, x_out_bce = eval_my_model(model_bce, test_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xl_mse, x_out_mse = eval_my_model(model_mse, test_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.gray()\n",
    "plt.figure()\n",
    "rs = 28\n",
    "i1 = np.random.randint(0, test_tensor.shape[0])\n",
    "i2 = np.random.randint(0, test_tensor.shape[0])\n",
    "fig, ax = plt.subplots(nrows=1, ncols=4, figsize=(4*4, 4))\n",
    "ax[0].set_title(\"real\")\n",
    "ax[0].imshow(test_tensor[i1].cpu().numpy().reshape((rs, rs)))\n",
    "ax[1].set_title(\"bce_recon\")\n",
    "ax[1].imshow(x_out_bce[i1].reshape((rs, rs)))\n",
    "ax[2].set_title(\"real\")\n",
    "ax[2].imshow(test_tensor[i2].cpu().numpy().reshape((rs,rs)))\n",
    "ax[3].set_title(\"bce_recon\")\n",
    "ax[3].imshow(x_out_bce[i2].reshape((rs, rs)))\n",
    "plt.figure()\n",
    "fig, ax = plt.subplots(nrows=1, ncols=4, figsize=(4*4, 4))\n",
    "ax[0].set_title(\"real\")\n",
    "ax[0].imshow(test_tensor[i1].cpu().numpy().reshape((rs, rs)))\n",
    "ax[1].set_title(\"mse_recon\")\n",
    "ax[1].imshow(x_out_mse[i1].reshape((rs, rs)))\n",
    "ax[2].set_title(\"real\")\n",
    "ax[2].imshow(test_tensor[i2].cpu().numpy().reshape((rs, rs)))\n",
    "ax[3].set_title(\"mse_recon\")\n",
    "ax[3].imshow(x_out_mse[i2].reshape((rs, rs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 2)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tt = xl_bce[:, 0, :]\n",
    "tt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 2, 1, 1)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tt.reshape(N, 2, 1, 1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt = torch.tensor(tt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10000, 10, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "class GG(torch.nn.Module):\n",
    "    def __init__(self, inch, ks):\n",
    "        super(GG, self).__init__()\n",
    "        self.up1 = torch.nn.Upsample(scale_factor=2.0, mode=\"bilinear\")\n",
    "        self.c1 = torch.nn.ConvTranspose2d(inch, 10, kernel_size=ks, stride=1, padding=1)\n",
    "        self.c2 = torch.nn.ConvTranspose2d(10, 11, kernel_size=ks, stride=1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.c1(x)\n",
    "    \n",
    "modelgg = GG(2, 5)\n",
    "\n",
    "modelgg.eval()\n",
    "with torch.no_grad():\n",
    "    y = modelgg(tt.reshape(tt.shape[0], tt.shape[1], 1, 1))\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = np.random.uniform(size=(3, 8, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.20447017, 0.23146137, 0.18647668, 0.9345052 , 0.30791861,\n",
       "         0.80190974, 0.66656578, 0.27355767],\n",
       "        [0.5698904 , 0.99766851, 0.57681253, 0.44415597, 0.48657245,\n",
       "         0.32621463, 0.9351906 , 0.15105242],\n",
       "        [0.93485643, 0.24018451, 0.21946419, 0.53879257, 0.37459136,\n",
       "         0.89789777, 0.03563021, 0.1806451 ],\n",
       "        [0.92437445, 0.58419348, 0.07457824, 0.25675984, 0.42193761,\n",
       "         0.48916177, 0.26734097, 0.96459561],\n",
       "        [0.64238615, 0.48582245, 0.84824348, 0.43621022, 0.26725068,\n",
       "         0.8770572 , 0.34462674, 0.02908932],\n",
       "        [0.00725171, 0.65550982, 0.45581096, 0.78850688, 0.54641903,\n",
       "         0.17908613, 0.05983656, 0.79877901],\n",
       "        [0.25597202, 0.2056959 , 0.96746292, 0.10267151, 0.41584128,\n",
       "         0.17034959, 0.96568276, 0.4885825 ],\n",
       "        [0.96968502, 0.98749816, 0.30671948, 0.63015331, 0.12766744,\n",
       "         0.6549342 , 0.50132981, 0.98169725]],\n",
       "\n",
       "       [[0.66678712, 0.48362487, 0.74795782, 0.47611962, 0.68585837,\n",
       "         0.3568814 , 0.53723097, 0.42929744],\n",
       "        [0.96512684, 0.90947384, 0.8845339 , 0.94059515, 0.52774971,\n",
       "         0.87346027, 0.80970524, 0.1773894 ],\n",
       "        [0.57227624, 0.38562284, 0.15472425, 0.71867084, 0.82106441,\n",
       "         0.66254922, 0.48061101, 0.24673428],\n",
       "        [0.67241704, 0.47873187, 0.3125925 , 0.87562017, 0.0308605 ,\n",
       "         0.36188385, 0.03076087, 0.2096996 ],\n",
       "        [0.51518052, 0.3287112 , 0.1903953 , 0.82364807, 0.26623683,\n",
       "         0.55280532, 0.30102989, 0.30593709],\n",
       "        [0.9001023 , 0.66549151, 0.39622736, 0.11556473, 0.83790919,\n",
       "         0.29856585, 0.29462311, 0.3926534 ],\n",
       "        [0.75088034, 0.92176346, 0.43334662, 0.26098285, 0.31164295,\n",
       "         0.48103902, 0.64700596, 0.21543538],\n",
       "        [0.95594032, 0.98404139, 0.93691629, 0.48578466, 0.01493513,\n",
       "         0.14538709, 0.38722098, 0.71219391]],\n",
       "\n",
       "       [[0.66364962, 0.05788693, 0.8736611 , 0.2935868 , 0.74604702,\n",
       "         0.09257199, 0.18848381, 0.62635445],\n",
       "        [0.15596597, 0.7957833 , 0.61169882, 0.15638824, 0.82575784,\n",
       "         0.45443657, 0.31283157, 0.79662727],\n",
       "        [0.64737509, 0.17275025, 0.62811193, 0.40542722, 0.8567297 ,\n",
       "         0.77356933, 0.58567775, 0.27021078],\n",
       "        [0.65281081, 0.41477497, 0.19942926, 0.17411805, 0.00318829,\n",
       "         0.19492118, 0.49513023, 0.44895218],\n",
       "        [0.68326299, 0.18422994, 0.56033154, 0.17654385, 0.44861786,\n",
       "         0.77782743, 0.32693146, 0.18826893],\n",
       "        [0.28123673, 0.06056924, 0.45962304, 0.2623708 , 0.00863539,\n",
       "         0.03724524, 0.59305664, 0.97812536],\n",
       "        [0.93267252, 0.49345577, 0.8161555 , 0.85629167, 0.17535627,\n",
       "         0.64576751, 0.13974922, 0.97137074],\n",
       "        [0.42102164, 0.20900598, 0.32344936, 0.29155207, 0.39318651,\n",
       "         0.47401671, 0.22814135, 0.25921417]]])"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "axes don't match array",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-181-3cfbff62aefc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\mauricio\\anaconda3\\envs\\color\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36mtranspose\u001b[1;34m(a, axes)\u001b[0m\n\u001b[0;32m    637\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    638\u001b[0m     \"\"\"\n\u001b[1;32m--> 639\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_wrapfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'transpose'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    640\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    641\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\mauricio\\anaconda3\\envs\\color\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36m_wrapfunc\u001b[1;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_wrapfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 56\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     57\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[1;31m# An AttributeError occurs if the object does not have\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: axes don't match array"
     ]
    }
   ],
   "source": [
    "plt.imshow(np.transpose(img, (-1, 0)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
